## 编码

什么是编码

编码是信息从一种形式或格式转换为另一种形式的过程，简单来讲就是语言的翻译过程。我们都知道计算机使用的是机器语言即二进制码，相信大部分人都无法流畅的阅读二进制码，于是为了能够让人类更好的理解计算机输出的结果就需要将机器语言转换为自然语言，比如英语、俄语和中文等。 这看似简单的语言转换过程随着计算机的普及与互联网化对语言字符的编码冲击也越来越大，编码规范的调整也伴随着整个计算机发展历史。

现代编码模型

为了能够更精确的描述在编码过程中各个产物的归属以便正确的描述产物所发挥的功能，于是多事之人将现代的编码整理为一套可以说明的模型而且分为五层之多。

现代编码模型之分层：

1. 抽象字符表(ACR:Abstract character repertoire) ：是一个系统支持的所有抽象字符的集合，简单来说就是该层规范要确定一个系统能够包含的字符和字符形式，比如Windows支持中文，那么它的抽象字符表一定有中文字符集合而且也适配不同编码方式指定具体是何字符。  支持的抽象字符

2. 编码字符集(CCS:Coded Character Set) ：是将字符集中每个字符映射到1个坐标(整数值对：x, y) 或者表示为1个非负整数。字符集及码位映射称为编码字符集。例如，在一个给定的字符表中，表示大写拉丁字母“A”的字符被赋予整数65、字符“B”是66，如此继续下去。简单来说这就是一个映射关系表，将一串码值映射到抽象字符表里的特定字符。将字符映射为码位

3. 字符编码表(CEF:Character Encoding Form) ：该层也称为”storage format”，对于一个包含几乎全球语言的字符集，比如Unicode字符集最多可以2的31次方个字符，用4个字节来存储一个，但是真的有必要在时时刻刻都使用4个字节来记录一个字符吗？很显然不是这样，比如拉丁字母“A”实际上需要二进制码01000001一个字节就可以表示，于是需要一种类似于压缩方式的方法来尽量用最少空间存储不同种类字符的方式比如后面会提到的UTF。所以这一层主要是描述字符编码所能采用的编码格式。字符编码能采用的编码格式

4. 字符编码方案(CES:Character Encoding Scheme) ：也称作”serialization format”，将定长的整型值(即码元) 映射到8位字节序列，以便编码后的数据的文件存储或网络传输。

5. 传输编码语法(transfer encoding syntax) ：用于处理上一层次的字符编码方案提供的字节序列。一般其功能包括两种：一种是把字节序列的值映射到一套更受限制的值域内，以满足传输环境的限制，例如Email传输时 Base64或者quoted-printable，都是把8位的字节编码为7位长的数据；另一种是压缩字节序列的值，如 LZW 或者 行程长度编码等无损压缩技术。

常用的编码

ASCII

ASCII(发音： [/ski/]) ，American Standard Code for Information Interchange，美国信息交换标准代码) 是基于拉丁字母的一套计算机编码系统。它主要用于显示现代英语，而其扩展版本 EASCII 则可以部分支持其他西欧语言，并等同于国际标准ISO/IEC 646]。 ASCII编码由1个字节8bit来标识字符编码表映射关系，如果按字节来算最多支持256个字符映射，但是由于最高位始终为0，支持的字符更少了。下图为编码表：

![img](http://cdn.ayusummer233.top/img/b17eca8065380cd7c6de41d15fdb933258828174.jpeg)

从图中可以看到，如果使用ASCII码表，将二进制高四位(0100) 低四位 (0001) 对应ASCII码表就得到了A字符，如果要得到I LOVE Y，计算机只需要得到二级制01001001(I) 00100000(空格) 01001100(L) 01001111(O) 01010110(V) 01000101(E) 00100000(空格) 01011001(Y) 。 ASCII码所对应的所有字符高四位首位都为0，所以ASCII码成功的用7个比特位就完成了计算机语言转换为自然语言(人类语言) 的壮举，这看起来很令人振奋，美国人天真的以为IPv4的最大数255.255.255.255(32位) 总计4,294,967,296个地址(其中还有些专用地址占去一小部分) 就能覆盖全球的网络设备。所以说当其他国家的语言比如中文、日文和阿拉伯文需要用计算机显示的时候就完全无法使用ASCII码如此少量的编码映射方式。

GB2312

1974年8月，中国开始了748工程，包括了用计算机来处理中文字，展开了各种研究工作，后来到1980年公布了 GB 2312-80汉字编码的国家标准。 GB 2312标准共收录6763个汉字 ，其中一级汉字3755个， 二级汉字3008个；同时收录了包括 拉丁字母、 希腊字母、 日文、平假名及片假名字母、 俄语在内的682个字符。 看起来GB2312已经很牛逼了，使用2个字节作为编码字符集的空间，但是6763个汉字是真的不够用啊。

GBK

我汉语博大精深，只有6763个字怎么够？于是GBK中在保证不和GB2312、ASCII冲突(即兼容GB2312和ASCII) 的前提下，也用每个字占据2字节的方式又编码了许多汉字。经过GBK编码后，可以表示的汉字达到了20902个，另有984个汉语标点符号、部首等。值得注意的是这20902个汉字还包含了繁体字。

尽管现在呼吁所有的程序都使用unicode编码，所有的网站都使用utf-8编码，来一个统一的国际规范。但仍然有很多，包括国内及国外(特别是非英语国家) 的一些cms，仍然使用着自己国家的一套编码，比如我国的gbk、gb2312，作为自己默认的编码类型。也有一些cms为了考虑老用户，推出了gbk和utf-8两个版本(例如:dedecms)    我们就以gbk字符编码为例，拉开帷幕。

GBK全称《汉字内码扩展规范》,gbk是一种多字符编码。他使用了双字节编码方案，因为双字节编码所以gbk编码汉字，占用2个字节。一个utf-8编码的汉字，占用3个字节。我们可以通过输出来验证这句话。

例如：0xD50x5C 对应了汉字“誠 ”，URL编码用百分号加字符的16进制编码表示字符，于是 %d5%5c 经URL解码后为“誠”。

GB18030

然而，GBK的两万多字也已经无法满足我们的需求了，还有更多可能你自己从来没见过的汉字需要编码。这时候显然只用2字节表示一个字已经不够用了(2字节最多只有65536种组合，然而为了和ASCII兼容，最高位不能为0就已经直接淘汰了一半的组合，只剩下3万多种组合无法满足全部汉字要求) 。因此GB18030多出来的汉字使用4字节编码。当然，为了兼容GBK，这个四字节的前两位显然不能与GBK冲突(实操中发现后两位也并没有和GBK冲突) 。我国在2000年和2005年分别颁布的两次GB18030编码，其中2005年的是在2000年基础上进一步补充。至此，GB18030编码的中文文件已经有七万多个汉字了，甚至包含了少数民族文字。

Unicode

在ASCII编码明显不够用后，美国国家标准学会又搞了几套ISO的编码规范来兼容其他中欧等国家的语言，但是兼容性还是有不少问题。最终美国加州的Unicode组织他们放大招搞了Unicode(万国码) 打算借此一统江湖，最早Unicode也是最高16位2字节来进行映射，经过几番修改最终可以以最长32位4字节的空间来映射最多2的31次方个字符。看起来一切完美了，当然如果以后有了星际旅行并不一定能够完全标识全宇宙的文字。

从上面这一大堆改动来看，不管中国还是美国，在处理位数上远远低估了后续可能产生的扩展性，你可能会觉得一早就用4个字节来标识全球所有字符就完事了费那么大劲来回改。给你看一幅图你或许就会明白为什么那时候的科学家那么谨小慎微了。如图：

![img](http://cdn.ayusummer233.top/img/a686c9177f3e6709bb4e6015c658a13bf9dc5537.jpeg)

1956年IBM的硬盘，可存储5MB的数据

UTF-8又是什么

Unicode确实是一套能够满足全球使用的字符集，但是难道真的需要每一个字符都占用4个字节吗？虽然现在的存储空间已经足够大了，但是4个字节一个字符的方式还是很不明智的，比如字符“A”二进制码01000001却需要以00000000000000000000000001000001的方式存储。这一定不是我们想要的。于是UTF(Unicode/UCS Transformation Format) 应运而生，UTF是字符编码五层次模型的第三层，通过特定的规则对Unicode字符编码进行一定的压缩和转换以便快捷传输。 UTF的代表就是UTF-16和UTF-8，千万不要以为UTF-16比UTF-8更厉害能够容纳更多字符，字符容纳数量都是是Unicode编码集所确定的范围，UTF只是通过不同的转换形式更快更高效的找到特定字符。而UFT-16 比较奇葩，它使用 2 个或者 4 个字节来存储。 对于 Unicode 编号范围在 0 ~ FFFF 之间的字符，UTF-16 使用两个字节存储，并且直接存储 Unicode 编号，不用进行编码转换，这跟 UTF-32 非常类似。 对于 Unicode 编号范围在 10000~10FFFF 之间的字符，UTF-32 使用四个字节存储，具体来说就是：将字符编号的所有比特位分成两部分，较高的一些比特位用一个值介于 D800~DBFF 之间的双字节存储，较低的一些比特位(剩下的比特位) 用一个值介于 DC00~DFFF 之间的双字节存储。

设计UTF-8编码表达方式的理由：

1、单字节字符的最高有效比特永远是0(大家可以看看其他编码方式如何别扭的兼容ASCII码的) ；

2、多字节序列中的首个字符组的几个最高有效比特决定了序列的长度。最高有效位为110的是2字节序列，而1110的是三字节序列，如此类推；

3、多字节序列中其余的字节中的首两个最高有效比特为10。

转换关系如下图：

![img](http://cdn.ayusummer233.top/img/f636afc379310a55c06fa6904bda7daf832610b4.jpeg)

这样我们根据所要兼容的语言不同根据UTF-8多字节最高有效比特去判断编码最终使用了多少个字节来存储，其余的字节也都满足最高有效比特为10的特点有了一定的纠错功能。 简单一些理解就是UTF-16就是通过2个字节16位来控制压缩比例，而UTF-8已经以高精度的1个字节8位来控制压缩比例了。当然还有中UTF-32就可想而知，基本跟Unicode如出一辙。

### UTF-8

1.

UTF-8编码是Unicode字符集的一种字符编码方式(CEF)，其特点是使用变长字节数(即变长码元序列或称变宽码元序列)来编码。目前一般是1到4个字节，当然，也可以更长。

为什么要变长呢？这可以理解为按需分配，比如一个字节足以容纳所有的ASCII字符，那何必补一堆0，导致占用更多的字节来存储呢？

实际上变长编码有其优势，也有其劣势，优势方面除了上面所讲的节省存储空间之外，还有就是自动纠错性能好、利于传输、扩展性强，而劣势方面主要是由于字符的编码字节数不固定导致不利于程序内部处理，比如导致正则表达式检索的复杂度大为增加；而UTF-32这样的等长码元序列(即等宽码元序列)的编码方式就比较适合程序处理，当然，缺点是比较耗费存储空间。

2.

那UTF-8究竟是怎么编码的呢？也就是说其编码算法是什么？

UTF-8编码最短的为一个字节、最长的目前为四个字节，从首字节就可以判断一个UTF-8编码有几个字节：

- 如果首字节以0开头，肯定是单字节编码(即单个单字节码元)；
- 如果首字节以110开头，肯定是双字节编码(即由两个单字节码元所组成的双码元序列)；
- 如果首字节以1110开头，肯定是三字节编码(即由三个单字节码元所组成的三码元序列)，以此类推。

另外，UTF-8编码中，除了单字节编码外，由多个单字节码元所组成的多字节编码其首字节以外的后续字节均以10开头(以区别于单字节编码以及多字节编码的首字节)。

0、110、1110以及10相当于UTF-8编码中各个字节的前缀，因此称之为前缀码。其中，前缀码110、1110及10中的0，是前缀码中的终结标志。

UTF-8编码中的前缀码起到了很好的区分和标识的作用：

- 当解码程序读取到一个字节的首位为0，表示这是一个单字节编码的ASCII字符；
- 当读取到一个字节的首位为1，表示这是一个非ASCII字符的多字节编码字符中的某个字节(可能是首字节，也可能是后续字节)，接下来若继续读取到一个1，则确定为首字节，再继续读取直到遇见终结标志0为止，读取了几个1，就表示该字符为几个字节的编码；
- 当读取到一个字节的首位为1，紧接着读取到一个终结标志0，则该字节显然是非ASCII字符的后续字节(即非首字节)。

3.

所以，1～4字节的UTF-8编码看起来分别是这样的：

![img](http://cdn.ayusummer233.top/img/v2-cfa67288f1f3e9cbd3a737970aa5fd27_b.jpg)

单字节可编码的Unicode码点值范围十六进制为0x0000 ~ 0x007F，十进制为0 ~ 127；

双字节可编码的Unicode码点值范围十六进制为0x0080 ~ 0x07FF，十进制为128 ~ 2047；

三字节可编码的Unicode码点值范围十六进制为0x0800 ~ 0xFFFF，十进制为2048 ~ 65535；

四字节可编码的Unicode码点值范围十六进制为0x10000 ~ 0x1FFFFF，十进制为65536 ~ 2097151(目前Unicode字符集码点编号的最大值为0x10FFFF，实际尚未编号到0x1FFFFF；这说明作为变长字节数的UTF-8编码其未来扩展性非常强，即便目前的四字节编码也还有大量编码空间未被使用，更不论还可扩展为五字节、六字节……) 。

([笨笨阿林原创文章](https://zhuanlan.zhihu.com/paogenjiudi)，转载请注明出处) 

4.

上述Unicode码点值范围中十进制值127、2047、65535、2097151这几个临界值是怎么来的呢？

因为UTF-8编码中的每个字节中都含有起到区分和标识之用的前缀码0、110、1110以及10之一，所以1～4个字节的UTF-8编码其实际有效位数分别为8-1=7位(2^7-1=127) 、16-5=11位(2^11-1=2047) 、24-8=16位(2^16-1=65535) 、32-11=21位(2^21-1=2097151) ，如下表所示：

![img](http://cdn.ayusummer233.top/img/v2-affb0b20e2d4b8dbabd912e83ba37748_b.png)

***注：**上图中的Unicode range为Unicode码点值范围(也就是Unicode码点编号范围)，Hex为16进制，Binary为二进制；Encoded bytes为UTF-8编码中各字节的编码方式(即编码算法)，其中，x代表Unicode二进制码点值的单字节或低字节中的低7位或8位、y代表两字节码点值的高字节中的低3位或8位以及三字节码点值的中字节中的8位、z代表三字节码点值的高字节中的低5位。*

因此，UTF-8编码的算法简单地来概括就是：首先确定UTF-8编码中各个字节的前缀码；之后再将UTF-8编码中各个字节除了前缀码所占用之外的位，依次分配给Unicode字符码点值二进制中各个位的值。换言之，就是用Unicode字符码点值二进制中各个位的值，依次填充UTF-8编码中的各个字节除了前缀码所占用之外的位。

5.

由于ASCII字符的UTF-8编码使用单字节，而且和ASCII编码一模一样，这样所有原先使用ASCII编码的文档就可以直接解码了，无需进行任何转换，实现了完全兼容。考虑到计算机世界里的英文文档数量之多，这一点意义重大。

而对于其他非ASCII字符，则使用2~4个字节的编码来表示。其中，首字节中前置的“1”的个数代表该字符编码的字节数(如110代表两个字节、1110代表三个字节，以此类推)，非首字节之外的剩余后续字节的前两位始终是10，这样就不会与ASCII字符编码(“0”开头)以及非ASCII字符的首字节编码(110或1110等至少两个“1”开头)相冲突。

例如，假设某个字符的首字节是1110yyyy，前置有三个1，说明该字符编码总共有三个字节，必须和后面两个以10开头的字节结合才能正确解码该字符。

6.

由此可知，**UTF-8编码设计得非常精巧**，虽说不上完美无瑕，但若与后文将要介绍的UTF-16、UTF-32以及前文介绍过的那些ANSI编码相比较，对于其精巧设计将体会得更为深切透彻。因此，**UTF-8越来越得到全球一致认可，大有一统字符编码之势**。

### URL和BASE64编码

[URL编码和Bsae64编码 - 阿玛度の博客 - 博客园 (cnblogs.com)](https://www.cnblogs.com/amadoGrowers/p/14692961.html)

[Base64和urlencode - 简书 (jianshu.com)](https://www.jianshu.com/p/b611e220ef2d?u_atoken=47310705-ed06-4f2e-8884-81ce61b0e3a5&u_asession=01gPfrHd1APy4DyVR1Wvdu-LsM7WXStg5d_PaH-8w0bjEEQdT2wJB38CY2mv6gNDcOX0KNBwm7Lovlpxjd_P_q4JsKWYrT3W_NKPr8w6oU7K9v9j91CaQ3649doiZwsE-MPIF6hypDqzN_tz02ZDuS7GBkFo3NEHBv0PZUm6pbxQU&u_asig=056p5cIcPIKtRzQlYqVpNFBQNrsQRiKxm7WCHjvHUadG2jp5gRjSIfNQkdeJUVHUwRLrCtcHQ6HgWubPM8JQT7NaxQZpv3SqKzRuLxVNqzcy_sCvNeoO93IBsG4dbJ553dn8Vsa4d60ca61JiKu01Dvjh2G4LDOy67iM_HPBpZmq79JS7q8ZD7Xtz2Ly-b0kmuyAKRFSVJkkdwVUnyHAIJzSE6lWjlDIOW2YF6a2hjwnsYh_1P_kJurkjDGiUspvR6HLC90DffcRgc58NhmjbgM-3h9VXwMyh6PgyDIVSG1W9nIaTuIPGC9Ew8Y10sjLbeM1CcDvpYE0FByRD-zGgt7Zv-pSH8sehbUCbKQO4aePbwQm735lou7bYHeWpUQDbWmWspDxyAEEo4kbsryBKb9Q&u_aref=6DmMT%2BauJGI0kocxvX3Jb469fsI%3D)

[用JS进行Base64编码、解码 - 简书 (jianshu.com)](https://www.jianshu.com/p/14437764eff3)

[js中对URL进行转码与解码_忍者小新的博客-CSDN博客_js中url解码](https://blog.csdn.net/WEB_CSDN_SHARE/article/details/79962996)



我们经常会遇到所谓的URL编码(也叫百分号编码) 和Base64编码。
    **先说一下Bsae64编码。**BASE64编码是一种常用的将二进制数据转换为64个可打印字符的编码，常用于在通常处理文本数据的场合，表示、传输、存储一些二进制数据。例如邮件系统的MIME协议等。这个协议的用途，是确保接收方在只能识别可见文本字符的情况下，能够接受和识别二进制数据。编码后数据长度大约为原长的135.1%。
    Base64编码是一种一对一的映射编码，其编码长度始终是3的倍数，不足3位，用=填充。所以，如果你看到一大堆乱七八糟的数据后面是=结尾的，大部分时候可以判定是Base64编码。由于Base64是映射编码，所以如果人为改变它的映射表，就可以作为一种简单的数据加密手段了。
    **再说一下URL编码**，这个编码通常用在网页地址(URL) 的传递中，在URL解释中，部分字符例如/ +等，有着特定的意义，因此不能直接使用Base64编码来传输地址文本。这个编码也适用于统一资源标志符(URI)的编码。URI所允许的字符分作保留与未保留。保留字符是那些具有特殊含义的字符. 例如, 斜线字符用于URL (或者更一般的, URI)不同部分的分界符，未保留字符没有这些特殊含义。 **URL编码把保留字符表示为%开头的特殊字符序列，所以又叫做百分号编码。**
    2005年1月发布的RFC 3986，强制所有新的URI必须对未保留字符不加以百分号编码；其它字符要先转换为UTF-8字节序列, 然后对其字节值使用百分号编码。但是在目前的实际应用中，一个URL地址在做百分号编码之前，其未保留的**字符序列不一定采用的是UTF-8编码，也有可能是ANSI编码。**此外，部分早期的系统将空格编码成+，而不是标准推荐的%20，这是我们在实际应用中应该注意的事项。

 

**一、URL编码和解码**

**1. escape 和 unescape**

escape()不能直接用于URL编码，它的真正作用是返回一个字符的Unicode编码值。

采用unicode字符集对指定的字符串除0-255以外进行编码。所有的空格符、标点符号、特殊字符以及更多有联系非ASCII字符都将被转化成%xx格式的字符编码(xx等于该字符在字符集表里面的编码的16进制数字) 。比如，空格符对应的编码是%20。
escape不编码字符有69个：*，+，-，.，/，@，_，0-9，a-z，A-Z。

escape()函数用于js对字符串进行编码，不常用。

```
　var url = "http://localhost:8080/pro?a=1&b=张三&c=aaa";
　　escape(url)  -->   http%3A//localhost%3A8080/pro%3Fa%3D1%26b%3D%u5F20%u4E09%26c%3Daaa
```

**2. encodeURI 和 decodeURI**

把URI字符串采用UTF-8编码格式转化成escape各式的字符串。
encodeURI不编码字符有82个：!，#，$，&，'，(，)，*，+，,，-，.，/，:，;，=，?，@，_，~，0-9，a-z，A-Z

 encodeURI()用于整个url编码

```
var url = "http://localhost:8080/pro?a=1&b=张三&c=aaa";
　　encodeURI(url)  -->   http://localhost:8080/pro?a=1&b=%E5%BC%A0%E4%B8%89&c=aaa 
```

**3. encodeURIComponent 和 decodeURIComponent**

与encodeURI()的区别是，它用于对URL的组成部分进行个别编码，而不用于对整个URL进行编码。

因此，"; / ? : @ & = + $ , #"，这些在encodeURI()中不被编码的符号，在encodeURIComponent()中统统会被编码。至于具体的编码方法，两者是一样。把URI字符串采用UTF-8编码格式转化成escape格式的字符串。

encodeURIComponent() 用于参数的传递，参数包含特殊字符可能会造成间断。

```
var url = "http://localhost:8080/pro?a=1&b=张三&c=aaa";
　　encodeURIComponent(url) --> http%3A%2F%2Flocalhost%3A8080%2Fpro%3Fa%3D1%26b%3D%E5%BC%A0%E4%B8%89%26c%3Daaa
 var paramUrl = "http://localhost:8080/aa?a=1&b=2&c=3";　　
    var url = "http://localhost:8080/pp?a=1&b="+ paramUrl;
    应该使用encodeURIComponent()进行转码　　
    encodeURIComponent(url) --> http://localhost:8080/pp?a=1&b=http%3A%2F%2Flocalhost%3A8080%2Faa%3Fa%3D1%26b%3D2%23%26c%3D3
```

原文链接：https://blog.csdn.net/WEB_CSDN_SHARE/article/details/79962996

### BASE64

使用base64的初衷。是为了方便把含有不可见字符串的信息用可见字符串表示出来

我们知道在计算机中任何数据都是按ascii码存储的，而ascii码的128～255之间的值是不可见字符。

而在网络上交换数据时，比如说从A地传到B地，往往要经过多个路由设备，由于不同的设备对字符的处理方式有一些不同，这样那些不可见字符就有可能被处理错误，这是不利于传输的。所以就先把数据先做一个Base64编码，统统变成可见字符，这样出错的可能性就大降低了

#### Base64编码的应用

1. 实现简单的数据加密，使用户一眼望去完全看不出真实数据内容，base64算法的复杂程度要小，效率要高相对较高。

2. Base64编码的主要的作用不在于安全性，而在于让内容能在各个网关间无错的传输，这才是Base64编码的核心作用。

3. 在计算机中任何数据都是按ascii码存储的，而ascii码的128～255之间的值是不可见字符。而在网络上交换数据时，比如说从A地传到B地，往往要经过多个路由设备，由于不同的设备对字符的处理方式有一些不同，这样那些不可见字符就有可能被处理错误，这是不利于传输的。所以就先把数据先做一个Base64编码，统统变成可见字符，这样出错的可能性就大降低了。

4. Base64 编码在URL中的应用：

   Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java持久化系统Hibernate中，就采用了Base64来将一个较长的唯一标识符(一般为128-bit的UUID) 编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为适合放在URL(包括隐藏表单域) 中的形式。此时，采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所直接看到。

   然而，**标准的Base64并不适合直接放在URL里传输**，因为URL编码器会把标准Base64中的“/”和“+”字符变为形如“%XX”的形式，而这些“%”号在存入数据库时还需要再进行转换，因为ANSI SQL中已将“%”号用作通配符。

   (1) 为解决此问题，可采用一种用于URL的改进Base64编码，它不在末尾填充'='号，并将标准Base64中的“+”和“/”分别改成了“-”和“*”，这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。 (2) 另有一种用于正则表达式的改进Base64变种，它将“+”和“/”改成了“!”和“-”，因为“+”，“*”以及前面在IRCu中用到的“[”和“]”在正则表达式中都可能具有特殊含义。 此外还有一些变种，它们将“+/”改为“*-”或“.*”(用作编程语言中的标识符名称) 或“.-”(用于XML中的Nmtoken) 甚至“*:”(用于XML中的Name) 。

   很多下载类网站都提供“迅雷下载”的链接，其地址通常是加密的迅雷专用下载地址。   如[thunder://QUFodHRwOi8vd3d3LmJhaWR1LmNvbS9pbWcvc3NsbTFfbG9nby5naWZaWg==](https://links.jianshu.com/go?to=thunder%3A%2F%2FQUFodHRwOi8vd3d3LmJhaWR1LmNvbS9pbWcvc3NsbTFfbG9nby5naWZaWg%3D%3D)   其实迅雷的“专用地址”也是用Base64加密的，其加密过程如下：

   - 一、在地址的前后分别添加AA和ZZ

   [如www.baidu.com/img/sslm1_logo.gif变成](https://links.jianshu.com/go?to=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fxn--www-eo8e.baidu.com%2Fimg%2Fsslm1_logo.gif%25E5%258F%2598%25E6%2588%2590) [AAwww.baidu.com/img/sslm1_l…](https://links.jianshu.com/go?to=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2FAAwww.baidu.com%2Fimg%2Fsslm1_logo.gifZZ)

   - 二、对新的字符串进行Base64编码

   [如AAwww.baidu.com/img/sslm1_logo.gifZZ用Base64编码得到QUFodHRwOi8vd3d3LmJhaWR1LmNvbS9pbWcvc3NsbTFfbG9nby5naWZaWg==](https://links.jianshu.com/go?to=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fxn--AAwww-gv5i.baidu.com%2Fimg%2Fsslm1_logo.gifZZ%25E7%2594%25A8Base64%25E7%25BC%2596%25E7%25A0%2581%25E5%25BE%2597%25E5%2588%25B0QUFodHRwOi8vd3d3LmJhaWR1LmNvbS9pbWcvc3NsbTFfbG9nby5naWZaWg%3D%3D)

   - 三、在上面得到的字符串前加上“thunder://”就成了

   [thunder://QUFodHRwOi8vd3d3LmJhaWR1LmNvbS9pbWcvc3NsbTFfbG9nby5naWZaWg==](https://links.jianshu.com/go?to=thunder%3A%2F%2FQUFodHRwOi8vd3d3LmJhaWR1LmNvbS9pbWcvc3NsbTFfbG9nby5naWZaWg%3D%3D)

**urlencode**

url编码主要是为了解决一些url中的一些特殊字符和歧义字符或者中文字符的传输问题，

#### 不能把base64 当作 urlencode

1. base64编码里面有一个 “+” 号，在urlecode编码中 “+” 会被解码成空格，urlencode时，"+" 号肯定是由空格编码出来的，但是base64编码的结果中 "+" 不是空格编码出来的，如果将base64编码作为安全的url编码使用，则 “+” 将被解码成空格，这是我们不愿看到的； 所以不要base64编码作为url编码来使用.

2. 我们知道http头里面可能会用base64编码来传输一些信息，因为这些信息不会被web服务器默认做url解码的，我们可以得到原始的编码信息，**所以http头里面使用base64编码是可以接受的**。

用base64编码后再进行URL编码，再传输可能会避免此类问题。

Base64编码将二进制数据按照每三个字节转换成四个字节可读字符，编码后的字符长度大约为136.1%。字符范围为 A-Z a-z 0-9 \ +。但编码后的字符串不太适合使用URL传输，中文加密后的乱码也多是因为这个原因引起：放在url中传输时+号会被替换成空格；并且每76个字符都会添加一个换行"\n"，这个换行符合会丢失。

例如：

哈哈哈哈哈哈。。。。

会被编码为：

uf65/rn+uf65/rn+oaOho6GjDQoNCrn+uf65/rn+uf65/qGjoaOhow0KDQq5/rn+uf65/rn+uf6h\no6GjoaM=

放在URL中传输时会变成(不是urlencode的意思，并没有urlencode) 

uf65/rn uf65/rn oaOho6GjDQoNCrn uf65/rn uf65/qGjoaOhow0KDQq5/rn uf65/rn uf6h

o6GjoaM=

解析肯定会出问题。

所以在传输和解密时要做如下处理：

1.去掉\n

2.替换空格为+

获取到的请求数据

eyJqb3NfcGFyYW1ldGVycyI6eyJhcHBfa2V5IjoiNDUyNDJFMkU0QjA3RTNCODcyRDExNjM1MTUyRjY1MzIiLCJlbmRfZGF0ZSI6MTQ2OTgwODAwMDAwMCwiaXRlbV9jb2RlIjoiRldfR09PRFMtNDY4MTAtMSIsInVzZXJfbmFtZSI6IueIseWxi awj WumOaWueaXl iIsOW6lyIsInZlcnNpb25fbm8iOjF9fQ==

#### base64能取代urlencode吗？

Base64编码 使用的字符包括大小写字母各26个，加上10个数字，和加号“+”，斜杠“/”，一共64个字符，等号“=”用来作为后缀用途。

其中的+, /, = 都是需要urlencode的，所以无法取代。

#### urlencode可以取代base64吗？

不能，base64有转码功能：

由于 ASCII 码称为了国际标准，所以我们要把其它字符转成 ASCII 就要用到 base64。

utf-8 -> base64(编码) -> ASCII
 ASCII -> base64(解码) -> utf-8

这样就可以让只支持 ASCII 的计算机支持 utf-8 了。



**一、Bsae64编码和解码**

**1. atob 和 btoa**

从IE10+浏览器开始，所有浏览器就原生提供了Base64编码、解码方法，不仅可以用于浏览器环境，Service Worker环境也可以使用。
方法名就是 atob 和 btoa ，具体语法如下：

```
window.btoa('china is so nb') // 编码
"Y2hpbmEgaXMgc28gbmI="
window.atob("Y2hpbmEgaXMgc28gbmI=") // 解码
"china is so nb"
```

**2.IE8/IE9的polyfill**

当下，仍有不少PC项目还需要兼容IE9，所以，我们可以专门针对这些浏览器再引入一段ployfill脚本或者一个JS文件即可。

if IE] 表示所有IE浏览器，由于IE10+浏览器已经放弃了著名的IE条件注释的支持，Chrome等浏览器本身就不支持这个IE私有语法，因此，很天然的，上面一段script引入只在IE9-浏览器下有效。而我们本来就希望只IE8，IE9浏览器引入ployfill，于是正好完美衔接上。

也就是原生支持atob和btoa方法的浏览器认为就是一段无需关心的HTML注释，不支持atob和btoa的IE9及其以下浏览器则会加载我们的base64-polyfill.js，使浏览器也支持 window.btoa 和 window.atob 这个语法。

```
<!--[if IE]>
<script src="https://www.zhangxinxu.com/wordpress/2018/08/js-base64-atob-btoa-encode-decode/base64-polyfill.js"></script>
<![endif]-->
```

**3.开源的base64.js** 

开源的base64.js使用很简单，浏览器引入该JS文件，然后Base64编码这样：

```
Base64.encode('china is so nb'); // 编码
"Y2hpbmEgaXMgc28gbmI="
```

解码就调用 `decode`方法，如下：

```
Base64.decode("Y2hpbmEgaXMgc28gbmI="); // 解码
'china is so nb'
```


